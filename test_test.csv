SETUP,,,,,,,,
Uncomment the cell below and run it if the imports do not work - or comment in lines where appropriate,,,,,,,,
In [1]:,,,,,,,,
!pip install git+git://github.com/moj-analytical-services/gluejobutils.git#egg=gluejobutils,,,,,,,,
!pip install git+git://github.com/moj-analytical-services/pydbtools.git#egg=pydbtools,,,,,,,,
!pip install altair==2.4.1,,,,,,,,
Requirement already satisfied: gluejobutils from git+git://github.com/moj-analytical-services/gluejobutils.git#egg=gluejobutils in /home/jovyan/.local/lib/python3.6/site-packages (1.0.4),,,,,,,,
Requirement already satisfied: pydbtools from git+git://github.com/moj-analytical-services/pydbtools.git#egg=pydbtools in /home/jovyan/.local/lib/python3.6/site-packages (1.0.3),,,,,,,,
Requirement already satisfied: numpy>=1.16.1 in /home/jovyan/.local/lib/python3.6/site-packages (from pydbtools) (1.16.4),,,,,,,,
Requirement already satisfied: gluejobutils>=v1.0.0 in /home/jovyan/.local/lib/python3.6/site-packages (from pydbtools) (1.0.4),,,,,,,,
Requirement already satisfied: s3fs>=0.2.2 in /home/jovyan/.local/lib/python3.6/site-packages (from pydbtools) (0.3.0),,,,,,,,
Requirement already satisfied: pandas>=0.23.4 in /opt/conda/lib/python3.6/site-packages (from pydbtools) (0.23.4),,,,,,,,
Requirement already satisfied: boto3>=1.7.4 in /opt/conda/lib/python3.6/site-packages (from pydbtools) (1.9.161),,,,,,,,
Requirement already satisfied: botocore>=1.12.91 in /opt/conda/lib/python3.6/site-packages (from s3fs>=0.2.2->pydbtools) (1.12.161),,,,,,,,
Requirement already satisfied: fsspec>=0.2.2 in /home/jovyan/.local/lib/python3.6/site-packages (from s3fs>=0.2.2->pydbtools) (0.3.4),,,,,,,,
Requirement already satisfied: python-dateutil>=2.5.0 in /opt/conda/lib/python3.6/site-packages (from pandas>=0.23.4->pydbtools) (2.7.5),,,,,,,,
Requirement already satisfied: pytz>=2011k in /opt/conda/lib/python3.6/site-packages (from pandas>=0.23.4->pydbtools) (2018.7),,,,,,,,
"Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /opt/conda/lib/python3.6/site-packages (from boto3>=1.7.4->pydbtools) (0.2.1)",,,,,,,,
"Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.6/site-packages (from boto3>=1.7.4->pydbtools) (0.9.4)",,,,,,,,
Requirement already satisfied: docutils>=0.10 in /opt/conda/lib/python3.6/site-packages (from botocore>=1.12.91->s3fs>=0.2.2->pydbtools) (0.14),,,,,,,,
"Requirement already satisfied: urllib3<1.26,>=1.20 in /opt/conda/lib/python3.6/site-packages (from botocore>=1.12.91->s3fs>=0.2.2->pydbtools) (1.23)",,,,,,,,
Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.6/site-packages (from python-dateutil>=2.5.0->pandas>=0.23.4->pydbtools) (1.11.0),,,,,,,,
Collecting altair==2.4.1,,,,,,,,
  Using cached https://files.pythonhosted.org/packages/3d/33/69f250e647ca16057a1256fbdb3828fb3f25df1a71b885df8e3f4986b263/altair-2.4.1-py2.py3-none-any.whl,,,,,,,,
Requirement already satisfied: pandas in /opt/conda/lib/python3.6/site-packages (from altair==2.4.1) (0.23.4),,,,,,,,
Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from altair==2.4.1) (1.11.0),,,,,,,,
Requirement already satisfied: jinja2 in /opt/conda/lib/python3.6/site-packages (from altair==2.4.1) (2.10),,,,,,,,
Requirement already satisfied: jsonschema in /opt/conda/lib/python3.6/site-packages (from altair==2.4.1) (3.0.0a3),,,,,,,,
Requirement already satisfied: entrypoints in /opt/conda/lib/python3.6/site-packages (from altair==2.4.1) (0.3),,,,,,,,
Requirement already satisfied: toolz in /opt/conda/lib/python3.6/site-packages (from altair==2.4.1) (0.9.0),,,,,,,,
Requirement already satisfied: numpy in /home/jovyan/.local/lib/python3.6/site-packages (from altair==2.4.1) (1.16.4),,,,,,,,
Requirement already satisfied: python-dateutil>=2.5.0 in /opt/conda/lib/python3.6/site-packages (from pandas->altair==2.4.1) (2.7.5),,,,,,,,
Requirement already satisfied: pytz>=2011k in /opt/conda/lib/python3.6/site-packages (from pandas->altair==2.4.1) (2018.7),,,,,,,,
Requirement already satisfied: MarkupSafe>=0.23 in /opt/conda/lib/python3.6/site-packages (from jinja2->altair==2.4.1) (1.1.0),,,,,,,,
Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.6/site-packages (from jsonschema->altair==2.4.1) (18.2.0),,,,,,,,
Requirement already satisfied: pyrsistent>=0.14.0 in /opt/conda/lib/python3.6/site-packages (from jsonschema->altair==2.4.1) (0.14.6),,,,,,,,
Installing collected packages: altair,,,,,,,,
Successfully installed altair-2.4.1,,,,,,,,
In [2]:,,,,,,,,
import pydbtools as dbt,,,,,,,,
import altair as alt,,,,,,,,
import pandas as pd,,,,,,,,
import sys,,,,,,,,
import os,,,,,,,,
"from functions.plotting import multi_line, multi_line_by_cat",,,,,,,,
"from IPython.display import display, Markdown",,,,,,,,
In [3]:,,,,,,,,
def get_sql(path):,,,,,,,,
    with open(path) as f:,,,,,,,,
        sql = ''.join(f.readlines()),,,,,,,,
    return sql,,,,,,,,
"def cast_double_to_int_str(df, colname):",,,,,,,,
    df['year'] = df['year'].astype(int).astype(str),,,,,,,,
    return df,,,,,,,,
def df_from_sql(sql):,,,,,,,,
    response = dbt.get_athena_query_response(sql),,,,,,,,
"    df = pd.read_csv(response['s3_path'], dtype = object)",,,,,,,,
    return df,,,,,,,,
def print_sql_as_markdown(path):,,,,,,,,
    sql = get_sql(path),,,,,,,,
    return Markdown('```sql\n' + sql + '```'),,,,,,,,
CREST published,,,,,,,,
Import data from C1 publication based on Crest data.,,,,,,,,
Note: This is frozen each year in June for the previous calandar year.,,,,,,,,
In [33]:,,,,,,,,
# Get pub numbers,,,,,,,,
p_rdos = pd.read_csv('data/CCSQ_rdos_2019Q2.csv'),,,,,,,,
"p_rdos['year_qtr'] = p_rdos[['year', 'quarter']].apply(lambda x: str(x[0]) + '-' + str(x[1]), axis=1)",,,,,,,,
p_rdos['source'] = 'publication_crest',,,,,,,,
p_receipts = p_rdos[p_rdos['disposal_type'] == 'receipts'],,,,,,,,
p_disposals = p_rdos[p_rdos['disposal_type'] == 'disposals'],,,,,,,,
p_outstanding = p_rdos[p_rdos['disposal_type'] == 'outstanding'],,,,,,,,
p_rdos.head(),,,,,,,,
Out[33]:,,,,,,,,
,year,quarter,receipt_type_desc,disposal_type,n,os_date,year_qtr,source
0,2012,1,app,disposals,3367,31/03/2012,2012-1,publication_crest
1,2012,2,app,disposals,3123,30/06/2012,2012-2,publication_crest
2,2012,3,app,disposals,3202,30/09/2012,2012-3,publication_crest
3,2012,4,app,disposals,3056,31/12/2012,2012-4,publication_crest
4,2012,1,ind,disposals,8528,31/03/2012,2012-1,publication_crest
HMCTS OPT/published MI,,,,,,,,
Import data from HMCTS OPT (10 Jan 2020 update).,,,,,,,,
Note: Data prior to 2019 Q2 is based on Crest data and frozen at the end of each financial year. Only data from 2019/2020 is extracted from Xhibit. Also the data for trials is not split by TEW and IND but combined and called committals.,,,,,,,,
In [35]:,,,,,,,,
# Get HMCTS numbers,,,,,,,,
h_rdos = pd.read_csv('data/HMCTS_rdos_20200110.csv'),,,,,,,,
"h_rdos['year_qtr'] = h_rdos[['year', 'quarter']].apply(lambda x: str(x[0]) + '-' + str(x[1]), axis=1)",,,,,,,,
h_rdos['source'] = 'hmcts_opt',,,,,,,,
h_receipts = h_rdos[h_rdos['disposal_type'] == 'receipts'],,,,,,,,
h_disposals = h_rdos[h_rdos['disposal_type'] == 'disposals'],,,,,,,,
h_outstanding = h_rdos[h_rdos['disposal_type'] == 'outstanding'],,,,,,,,
h_rdos.head(),,,,,,,,
Out[35]:,,,,,,,,
,year,quarter,receipt_type_desc,disposal_type,n,os_date,year_qtr,source
0,2019,1,committals,receipts,15365,31/03/2019,2019-1,hmcts_opt
1,2018,1,committals,receipts,15469,31/03/2018,2018-1,hmcts_opt
2,2017,1,committals,receipts,18858,31/03/2017,2017-1,hmcts_opt
3,2016,1,committals,receipts,19477,31/03/2016,2016-1,hmcts_opt
4,2015,1,committals,receipts,23113,31/03/2015,2015-1,hmcts_opt
FF Receipts,,,,,,,,
"Based on query from xhibit-database-status, updating to extract from the test database xhibit_der_dev.",,,,,,,,
In [28]:,,,,,,,,
#Get Xhibit numbers from xhibit_der_dev,,,,,,,,
x_rec_sql = get_sql('sql/receipts/xhibit-receipts.sql'),,,,,,,,
x_rec = df_from_sql(x_rec_sql),,,,,,,,
"x_rec['year_qtr'] = x_rec[['year', 'quarter']].apply(lambda x: str(x[0]) + '-' + str(x[1]), axis=1)",,,,,,,,
x_rec['source'] = 'ff_xhibit',,,,,,,,
x_rec.head(),,,,,,,,
Out[28]:,,,,,,,,
,year,quarter,receipt_type_desc,n,year_qtr,source,,
0,2012,1,app,1118,2012-1,ff_xhibit,,
1,2012,1,ind,4629,2012-1,ff_xhibit,,
2,2012,1,sent,4152,2012-1,ff_xhibit,,
3,2012,1,tew,5902,2012-1,ff_xhibit,,
4,2012,2,app,1383,2012-2,ff_xhibit,,
CCSQ Xhibit Receipts,,,,,,,,
Code run from xhibit to extract published receipts.,,,,,,,,
In [51]:,,,,,,,,
#Get Xhibit numbers from xhibit_v1,,,,,,,,
x_rec_sql_ccsq = get_sql('sql/receipts/ccsq-receipts.sql'),,,,,,,,
x_rec_ccsq = df_from_sql(x_rec_sql_ccsq),,,,,,,,
x_rec_ccsq['n'] = x_rec_ccsq['n'].astype(int),,,,,,,,
"x_rec_ccsq['year_qtr'] = x_rec_ccsq[['year', 'quarter']].apply(lambda x: str(x[0]) + '-' + str(x[1]), axis=1)",,,,,,,,
x_rec_ccsq['source'] = 'ccsq_xhibit',,,,,,,,
x_rec_ccsq.head(),,,,,,,,
Out[51]:,,,,,,,,
,year,quarter,receipt_type_desc,n,year_qtr,source,,
0,2012,1,app,1119,2012-1,ccsq_xhibit,,
1,2012,1,ind,4691,2012-1,ccsq_xhibit,,
2,2012,1,sent,4573,2012-1,ccsq_xhibit,,
3,2012,1,tew,6097,2012-1,ccsq_xhibit,,
4,2012,2,app,1400,2012-2,ccsq_xhibit,,
Compare receipts,,,,,,,,
Plot the receipts trends of xhibit vs publication,,,,,,,,
In [52]:,,,,,,,,
from functions.plotting import multi_line_by_cat,,,,,,,,
"receipts = pd.concat([p_receipts,h_receipts, x_rec, x_rec_ccsq], sort=True)",,,,,,,,
"multi_line(receipts, x='year_qtr:O', y='sum(n)', colour = 'source:N', title='receipts xhibit vs published')",,,,,,,,
Out[52]:,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
In the readme we discuss the difference between the methodology between in published figures and defendant_summary. The biggest difference is how the published measures calculate receipts volumes:,,,,,,,,
mags_in + cc_in - cc_out + bws,,,,,,,,
mags_in = Cases recieved from mags court,,,,,,,,
cc_in = Cases receieved from a different Crown Court,,,,,,,,
cc_out = Cases sent to another Crown Court,,,,,,,,
bws = Bench warrants received at the Crown Court,,,,,,,,
In our measure trend above there are 3 main things to investigate in the differences:,,,,,,,,
Number of cases double counted in published stats (out of scope of this as we cannot get the low level numbers). If I recall this double counting was a low proportion when aggregatted at a high level (so would only account for less than 0.5% would be my guess),,,,,,,,
Proportion of bench warrant receipts that are not counted in our total,,,,,,,,
proportion of cases transferred out that are not counted in our total,,,,,,,,
Bench warrant receipts,,,,,,,,
Lets run some sql to get the total number of receipts from the defendant_summary and add on bench warrants.,,,,,,,,
Additional methodological note:,,,,,,,,
"bench_warrants in the publication code are added to the cases receipt volume. However, bench_warrants are on a defendant basis which means that you are adding a case volume to a defendant volume. Although this is wrong bench warrant volumes are marginal so the correction to this will not cause too big of a difference to overall volumes.",,,,,,,,
We try to measure bench_warrants on a case basis in our volumes below:,,,,,,,,
In [12]:,,,,,,,,
"print_sql_as_markdown(""sql/receipts/xhibit-bw-receipts.sql"")",,,,,,,,
Out[12]:,,,,,,,,
WITH bw AS (,,,,,,,,
"  SELECT defendant_on_case_id, bw_end_date",,,,,,,,
  FROM xhibit_v1.bw_history,,,,,,,,
"  WHERE COALESCE(obs_ind, 'N') <> 'Y' AND dea_latest_record AND bw_end_date IS NOT NULL",,,,,,,,
  AND year(bw_end_date) >= 2012 and year(bw_end_date) <= 2017,,,,,,,,
"),",,,,,,,,
rt AS (,,,,,,,,
"  SELECT ff.defendant_on_case_id, ff.case_id, ff.receipt_type_desc, bw.bw_end_date",,,,,,,,
  FROM xhibit_v1.defendant_summary as ff,,,,,,,,
  INNER JOIN bw,,,,,,,,
  ON ff.defendant_on_case_id = bw.defendant_on_case_id,,,,,,,,
  WHERE ff.single_case_flag,,,,,,,,
),,,,,,,,
"SELECT year(bw_end_date) as year, quarter(bw_end_date) as quarter, receipt_type_desc, count(*) as n",,,,,,,,
FROM rt,,,,,,,,
"GROUP BY year(bw_end_date), quarter(bw_end_date), receipt_type_desc",,,,,,,,
So looking at this code it appears to only count the bench warrant if it is for the main defendant. I have tweaked the code so that it should count a BW on a case no matter which defendant it is on.,,,,,,,,
"Check: Karik, is this right?",,,,,,,,
In [18]:,,,,,,,,
"print_sql_as_markdown(""sql/receipts/xhibit-bw-receipts-altered.sql"")",,,,,,,,
Out[18]:,,,,,,,,
WITH bw AS (,,,,,,,,
"  SELECT defendant_on_case_id, bw_end_date",,,,,,,,
  FROM xhibit_v1.bw_history,,,,,,,,
"  WHERE COALESCE(obs_ind, 'N') <> 'Y' AND mojap_start_datetime <= date '2020-02-11' AND mojap_end_datetime > date '2020-02-11' AND bw_end_date IS NOT NULL",,,,,,,,
  AND year(bw_end_date) >= 2012 and year(bw_end_date) <= 2019,,,,,,,,
"),",,,,,,,,
rt AS (,,,,,,,,
"  SELECT DISTINCT ff.case_id, ff.receipt_type_desc, bw.bw_end_date",,,,,,,,
  FROM xhibit_der_dev.defendant_summary as ff,,,,,,,,
  INNER JOIN bw,,,,,,,,
  ON ff.defendant_on_case_id = bw.defendant_on_case_id,,,,,,,,
  WHERE mojap_snapshot_date = date '2020-02-12' and case_type <> 'A' and year(ff.receipt_date) > 2011 and year(ff.receipt_date) < 2020,,,,,,,,
),,,,,,,,
"SELECT year(bw_end_date) as year, quarter(bw_end_date) as quarter, receipt_type_desc, count(*) as n",,,,,,,,
FROM rt,,,,,,,,
"GROUP BY year(bw_end_date), quarter(bw_end_date), receipt_type_desc",,,,,,,,
In [31]:,,,,,,,,
#Get bw Xhibit numbers from xhibit_v1,,,,,,,,
"x_bw_rec_a_sql = get_sql(""sql/receipts/xhibit-bw-receipts-altered.sql"")",,,,,,,,
x_bw_rec_a = df_from_sql(x_bw_rec_a_sql),,,,,,,,
x_bw_rec_a.head(),,,,,,,,
Out[31]:,,,,,,,,
,year,quarter,receipt_type_desc,n,,,,
0,2015,1,sent,632,,,,
1,2014,3,sent,618,,,,
2,2015,1,ind,301,,,,
3,2014,3,ind,282,,,,
4,2015,4,sent,591,,,,
I suspect these numbers are higher than previously thought for two reasons:,,,,,,,,
data has migrated over to the Xhibit system and;,,,,,,,,
"as the query has changed to count if any defendant has a BW on the case, not only if the main defendant has a BW.",,,,,,,,
Originally Crest information was used as a proxy for the BW's but we will stick with xhibit here as all the data should be migrated over.,,,,,,,,
It is also worth noting that xhb bench warrants for appeals is low to non-existent see this issue. In the published stats BW against appeals are not included in the receipts count - so these will be excluded in this analysis.,,,,,,,,
CHECK EXCLUSION OF BW APPEALS: BW against appeals are not included in the receipts count. Does anyone know why? Is this a valid exclusion? Is it because we do not expect BW on appeals so have excluded them as DQ?,,,,,,,,
Let's use the xhibit bw excluding appeals for the estimate.,,,,,,,,
In [53]:,,,,,,,,
"x_rec_plus_bw = pd.merge(x_rec, x_bw_rec_a, how='outer', on=['year', 'quarter', 'receipt_type_desc'])",,,,,,,,
"x_rec_plus_bw = x_rec_plus_bw.rename(columns={'n_x': 'x_n', 'n_y': 'bw_n'}).fillna(0)",,,,,,,,
x_rec_plus_bw['x_n'] = x_rec_plus_bw['x_n'].astype(int),,,,,,,,
x_rec_plus_bw['bw_n'] = x_rec_plus_bw['bw_n'].astype(int),,,,,,,,
x_rec_plus_bw['n'] = x_rec_plus_bw['x_n'] + x_rec_plus_bw['bw_n'],,,,,,,,
"x_rec_plus_bw = x_rec_plus_bw.drop(['x_n', 'bw_n'], axis=1)",,,,,,,,
"receipts2 = pd.concat([p_receipts, h_receipts, x_rec_ccsq, x_rec_plus_bw], sort=True)",,,,,,,,
"multi_line(receipts2, x='year_qtr:O', y='sum(n)', colour='source:N', title='receipts xhibit vs published (accounting for bw - only)')",,,,,,,,
Out[53]:,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
So ff_xhibit receipts are looking a bit high now. It may be the way we count trans in and trans out causing this disparency.,,,,,,,,
Let's measure the % differences from the currently published ccsq_receipts to (ff_xhibit + bws). Published ccsq_receipts are pretty similar to publication_crest and hmcts_opt so have picked just the one measure to compare.,,,,,,,,
In [54]:,,,,,,,,
"rec_comp = receipts2.groupby(by=['year_qtr', 'source']).sum().reset_index()",,,,,,,,
"rec_comp = rec_comp.set_index(['year_qtr', 'source']).unstack()",,,,,,,,
rec_comp = rec_comp['n'].reset_index(),,,,,,,,
# Filter out first quarter of 2012 as data is missing,,,,,,,,
rec_comp = rec_comp[rec_comp['year_qtr'] != '2012-1'],,,,,,,,
rec_comp['p_diff'] = (rec_comp['ff_xhibit'] - rec_comp['ccsq_xhibit'])/rec_comp['ccsq_xhibit'],,,,,,,,
alt.Chart(rec_comp).mark_bar().encode(,,,,,,,,
"    x='year_qtr',",,,,,,,,
"    y=alt.Y('p_diff:Q', axis=alt.Axis(format='%')),",,,,,,,,
    color=alt.condition(,,,,,,,,
"        abs(alt.datum.p_diff) <= 0.02,",,,,,,,,
"        alt.value(""steelblue""),  # The positive color",,,,,,,,
"        alt.value(""red"")  # The negative color",,,,,,,,
"    ),",,,,,,,,
"    tooltip=['p_diff', 'year_qtr']",,,,,,,,
").properties(width=600, title='Percentage difference xhibit vs crest receipts')",,,,,,,,
Out[54]:,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
Transferred out receipts,,,,,,,,
In the published measures we also subtract transferred out cases from the receipts count. To account for that to best measures the differences in the flatfile we can minus transferred out date. (Transferred in are already accounted for in receipts in the FF).,,,,,,,,
"When this was first run, not all courts had moved over so CREST was used to proxy this measure. I will exclude this from this analysis as all courts have now migrated.",,,,,,,,
In [56]:,,,,,,,,
"print_sql_as_markdown(""sql/receipts/xhibit-trans-out-receipts.sql"")",,,,,,,,
Out[56]:,,,,,,,,
"select year(case_disposal_date) as year, quarter(case_disposal_date) as quarter, receipt_type_desc, count(*) as n",,,,,,,,
from xhibit_der_dev.defendant_summary,,,,,,,,
where mojap_snapshot_date = date '2020-02-12' and year(case_disposal_date) > 2011 and year(case_disposal_date) < 2020 and single_case_flag and  disposal_type = 'transferred_out',,,,,,,,
"group by year(case_disposal_date), quarter(case_disposal_date), receipt_type_desc",,,,,,,,
"order by year(case_disposal_date), quarter(case_disposal_date), receipt_type_desc",,,,,,,,
In [57]:,,,,,,,,
"x_to_rec_sql = get_sql(""sql/receipts/xhibit-trans-out-receipts.sql"")",,,,,,,,
x_to_rec = df_from_sql(x_to_rec_sql),,,,,,,,
x_to_rec.head(),,,,,,,,
Out[57]:,,,,,,,,
,year,quarter,receipt_type_desc,n,,,,
0,2012,1,app,4,,,,
1,2012,1,ind,55,,,,
2,2012,1,sent,12,,,,
3,2012,1,tew,61,,,,
4,2012,2,app,2,,,,
Let's add this to the standard flatfile receipts count,,,,,,,,
In [59]:,,,,,,,,
"x_rec_plus_to = pd.merge(x_rec, x_to_rec, how='outer', on=['year', 'quarter', 'receipt_type_desc'])",,,,,,,,
"x_rec_plus_to = x_rec_plus_to.rename(columns={'n_x': 'x_n', 'n_y': 'to_n'}).fillna(0)",,,,,,,,
x_rec_plus_to['x_n'] = x_rec_plus_to['x_n'].astype(int),,,,,,,,
x_rec_plus_to['to_n'] = x_rec_plus_to['to_n'].astype(int),,,,,,,,
x_rec_plus_to['n'] = x_rec_plus_to['x_n'] - x_rec_plus_to['to_n'],,,,,,,,
"x_rec_plus_to = x_rec_plus_to.drop(['x_n', 'to_n'], axis=1)",,,,,,,,
"receipts3 = pd.concat([x_rec_ccsq, x_rec_plus_to], sort=True)",,,,,,,,
"multi_line(receipts3, x='year_qtr:O', y='sum(n)', colour = 'source:N', title='receipts xhibit vs published (accounting for trans_out)')",,,,,,,,
Out[59]:,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
Now lets compare trends accounting for bw and transferred out cases.,,,,,,,,
In [61]:,,,,,,,,
"x_rec_plus_both = pd.merge(x_rec_plus_bw, x_to_rec, how='outer', on=['year', 'quarter', 'receipt_type_desc'])",,,,,,,,
"x_rec_plus_both = x_rec_plus_both.rename(columns={'n_x': 'x_n', 'n_y': 'to_n'}).fillna(0)",,,,,,,,
x_rec_plus_both['x_n'] = x_rec_plus_both['x_n'].astype(int),,,,,,,,
x_rec_plus_both['to_n'] = x_rec_plus_both['to_n'].astype(int),,,,,,,,
x_rec_plus_both['n'] = x_rec_plus_both['x_n'] - x_rec_plus_both['to_n'],,,,,,,,
"x_rec_plus_both = x_rec_plus_both.drop(['x_n', 'to_n'], axis=1)",,,,,,,,
"receipts4 = pd.concat([x_rec_ccsq, x_rec_plus_both], sort=True)",,,,,,,,
"multi_line(receipts4, x='year_qtr:O', y='sum(n)', colour = 'source:N', title='receipts xhibit vs published (accounting for trans_out and bw)')",,,,,,,,
Out[61]:,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
In [63]:,,,,,,,,
"rec_comp_all = receipts4.groupby(by=['year_qtr','source']).sum().reset_index()",,,,,,,,
"rec_comp_all = rec_comp_all.set_index(['year_qtr','source']).unstack()",,,,,,,,
rec_comp_all = rec_comp_all['n'].reset_index(),,,,,,,,
# Filter out first quarter of 2012 as data is missing,,,,,,,,
rec_comp_all = rec_comp_all[rec_comp_all['year_qtr'] != '2012-1'],,,,,,,,
rec_comp_all['p_diff'] = (rec_comp_all['ff_xhibit'] - rec_comp_all['ccsq_xhibit'])/rec_comp_all['ccsq_xhibit'],,,,,,,,
alt.Chart(rec_comp_all).mark_bar().encode(,,,,,,,,
"    x='year_qtr',",,,,,,,,
"    y=alt.Y('p_diff:Q', axis=alt.Axis(format='%')),",,,,,,,,
    color=alt.condition(,,,,,,,,
"        abs(alt.datum.p_diff) <= 0.02,",,,,,,,,
"        alt.value(""steelblue""),  # The positive color",,,,,,,,
"        alt.value(""red"")  # The negative color",,,,,,,,
"    ),",,,,,,,,
"    tooltip=['p_diff', 'year_qtr']",,,,,,,,
").properties(width=600, title='Percentage difference xhibit vs crest receipts (accounting for both bw and trans out)')",,,,,,,,
Out[63]:,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
As you can see from the above the differnces are below 0.4% between the current publication and xhibit.,,,,,,,,
Below we do further breakdowns based on receipt type for reference:,,,,,,,,
(Note we exclude 2012-1 to make the plots axis better),,,,,,,,
In [64]:,,,,,,,,
"rec_comp_all2 = receipts4.groupby(by=['year_qtr','receipt_type_desc','source']).sum().reset_index()",,,,,,,,
"rec_comp_all2 = rec_comp_all2.set_index(['year_qtr','receipt_type_desc','source']).unstack()",,,,,,,,
rec_comp_all2 = rec_comp_all2['n'].reset_index(),,,,,,,,
# Filter out first quarter of 2012 as data is missing,,,,,,,,
rec_comp_all2 = rec_comp_all2[rec_comp_all2['year_qtr'] != '2012-1'],,,,,,,,
rec_comp_all2['p_diff'] = (rec_comp_all2['ff_xhibit'] - rec_comp_all2['ccsq_xhibit'])/rec_comp_all2['ccsq_xhibit'],,,,,,,,
In [66]:,,,,,,,,
def get_receipts_line_and_bar(cat):,,,,,,,,
    df1 = receipts4[(receipts4['receipt_type_desc'] == cat) & (receipts4['year_qtr'] != '2012-1')],,,,,,,,
"    df1.drop(['year','quarter', 'receipt_type_desc'], axis=1)",,,,,,,,
    df2 = rec_comp_all2[(rec_comp_all2['receipt_type_desc'] == cat) & (rec_comp_all2['year_qtr'] != '2012-1')],,,,,,,,
"    ml = multi_line(df1, x='year_qtr:O', y='sum(n)', colour = 'source:N')",,,,,,,,
    ,,,,,,,,
    bar = alt.Chart(df2).mark_bar().encode(,,,,,,,,
"    x='year_qtr',",,,,,,,,
"    y=alt.Y('p_diff:Q', axis=alt.Axis(format='%')),",,,,,,,,
    color=alt.condition(,,,,,,,,
"        abs(alt.datum.p_diff) <= 0.02,",,,,,,,,
"        alt.value(""steelblue""),  # The positive color",,,,,,,,
"        alt.value(""red"")  # The negative color",,,,,,,,
"        ),",,,,,,,,
"        tooltip=['p_diff', 'year_qtr', 'receipt_type_desc']",,,,,,,,
    ).properties(width=600),,,,,,,,
    ,,,,,,,,
    return ml & bar,,,,,,,,
"for r in ['ind', 'tew', 'sent', 'app']:",,,,,,,,
display(Markdown(f'**Published vs Xhibit (receipt_type_desc: {r})**')),,,,,,,,
    display(get_receipts_line_and_bar(r)),,,,,,,,
Published vs Xhibit (receipt_type_desc: ind),,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
Published vs Xhibit (receipt_type_desc: tew),,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
Published vs Xhibit (receipt_type_desc: sent),,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
Published vs Xhibit (receipt_type_desc: app),,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
Not sure what is wrong with appeals needs more investigation. It especially seems to affect data since we have moved over to xhibit. But these are very small numbers so have v little affect overall.,,,,,,,,
Final receipts counts - publised vs xhibit,,,,,,,,
The above plots attempt to explain the difference between the xhibit flatfile (aka defendant_summary table) and the published figures.,,,,,,,,
However the new methodology for receipts is suggested as total cases received from mags and other crown courts. The bench warrant receipts and disposals should be a seperate table as bench warrants can be multiple per defendant - so it works on the same listing measures of bw events over a time period rather than part of the flatfile.,,,,,,,,
It can be seen that the ccsq way of counting receipts can be applied successfully to the flatfile to produce a measure which is consistent with the historic data series.,,,,,,,,
Disposals,,,,,,,,
FF Disposals,,,,,,,,
"Based on query from xhibit-database-status, updating to extract from the test database xhibit_der_dev.",,,,,,,,
"This database has case_disposal_date in line with HMCTS and CCSQ disposals in that we take the minimum date of each offence of the case, and then take the maximum value of these. This should reflect the first time that the case has been fully disposed of.",,,,,,,,
Caveat:,,,,,,,,
There will still be slight differences in methodology due to,,,,,,,,
"the way we count or discount BW, for example CCSQ will count a case as disposed of if all offences associated with each defendant that has no BW are outcomed and the other defendants have an os BW on them. we can try to account for this difference but it will not be perfect.",,,,,,,,
"HMCTS count a disposal if the case has had no action in a 12 month period, whereas ccsq and ff only apply this criteria to our outstanding measure.",,,,,,,,
There will be other differences that i have not fully accounted for,,,,,,,,
In [97]:,,,,,,,,
#Get Xhibit numbers from xhibit_der_dev,,,,,,,,
x_disp_sql = get_sql('sql/disposals/xhibit-disposals.sql'),,,,,,,,
x_disp = df_from_sql(x_disp_sql),,,,,,,,
"x_disp['year_qtr'] = x_disp[['year', 'quarter']].apply(lambda x: str(x[0]) + '-' + str(x[1]), axis=1)",,,,,,,,
x_disp['source'] = 'ff_xhibit',,,,,,,,
x_disp.head(),,,,,,,,
Out[97]:,,,,,,,,
,year,quarter,receipt_type_desc,n,year_qtr,source,,
0,2012,1,app,1803,2012-1,ff_xhibit,,
1,2012,1,ind,3227,2012-1,ff_xhibit,,
2,2012,1,sent,5869,2012-1,ff_xhibit,,
3,2012,1,tew,6881,2012-1,ff_xhibit,,
4,2012,2,app,604,2012-2,ff_xhibit,,
FF Disposals old,,,,,,,,
"Based on query from xhibit-database-status, updating to extract from the test database xhibit_der_v1. This is to look at the movement of the disposal change.",,,,,,,,
In [94]:,,,,,,,,
#Get Xhibit numbers from xhibit_der_v1 for comparison purposes,,,,,,,,
x_disp_sql_old = get_sql('sql/disposals/xhibit-disposals-old.sql'),,,,,,,,
x_disp_old = df_from_sql(x_disp_sql_old),,,,,,,,
"x_disp_old['year_qtr'] = x_disp_old[['year', 'quarter']].apply(lambda x: str(x[0]) + '-' + str(x[1]), axis=1)",,,,,,,,
x_disp_old['source'] = 'ff_xhibit_old',,,,,,,,
x_disp_old.head(),,,,,,,,
Out[94]:,,,,,,,,
,year,quarter,receipt_type_desc,n,year_qtr,source,,
0,2012,1,app,1803,2012-1,ff_xhibit_old,,
1,2012,1,ind,3113,2012-1,ff_xhibit_old,,
2,2012,1,sent,5833,2012-1,ff_xhibit_old,,
3,2012,1,tew,6724,2012-1,ff_xhibit_old,,
4,2012,2,app,604,2012-2,ff_xhibit_old,,
CCSQ Xhibit Disposals,,,,,,,,
Code run from xhibit to extract published disposals.,,,,,,,,
In [91]:,,,,,,,,
#Get Xhibit numbers from xhibit_v1,,,,,,,,
x_disp_sql_ccsq = get_sql('sql/disposals/xhibit-disposals-ccsq.sql'),,,,,,,,
x_disp_ccsq = df_from_sql(x_disp_sql_ccsq),,,,,,,,
x_disp_ccsq['n'] = x_disp_ccsq['n'].astype(int),,,,,,,,
"x_disp_ccsq['year_qtr'] = x_rec_ccsq[['year', 'quarter']].apply(lambda x: str(x[0]) + '-' + str(x[1]), axis=1)",,,,,,,,
x_disp_ccsq['source'] = 'ccsq_xhibit',,,,,,,,
x_disp_ccsq.head(),,,,,,,,
Out[91]:,,,,,,,,
,year,quarter,receipt_type_desc,n,year_qtr,source,,
0,2012,1,app,1879,2012-1,ccsq_xhibit,,
1,2012,1,ind,4426,2012-1,ccsq_xhibit,,
2,2012,1,sent,6438,2012-1,ccsq_xhibit,,
3,2012,1,tew,8471,2012-1,ccsq_xhibit,,
4,2012,2,app,619,2012-2,ccsq_xhibit,,
Compare disposals,,,,,,,,
Plot the disposal trends of xhibit vs publication,,,,,,,,
In [98]:,,,,,,,,
"disposals = pd.concat([p_disposals, h_disposals, x_disp, x_disp_old, x_disp_ccsq], sort=True)",,,,,,,,
"multi_line(disposals, x='year_qtr:O', y='sum(n)', colour = 'source:N', title='disposals xhibit vs published')",,,,,,,,
Out[98]:,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
From the initial basic comparision we have less disposals in the flatfile compared to the published. This is similar to the receipt trends all be it with a larger gap.,,,,,,,,
The key differences in methodology to investigate are outlined below (again please refer to the README for changes in the flow models):,,,,,,,,
Date closed no longer exists in xhibit. This was used as a catch all for completed cases so we need to investigate new proxys for this measure.,,,,,,,,
The xhibit.defendant_summary table counts transferred out cases as disposals. The publication doesn't - they are counted as negative receipts.,,,,,,,,
The publication counts BWs being issued as a disposal. defendant_summary doesn't so again we need to proxy to explain differences.,,,,,,,,
Overall you would imagine to see that there a relative increase in disposals due to counting transferred out but also a decrease due to not counting bench warrants. How this results in an overall difference depends on the volume of each,,,,,,,,
Bench Warrant Disposals,,,,,,,,
Lets run some sql to get the total number of receipts from the defendant_summary and add on bench warrants as how they are counted from the publication. We are going to use the disposal_summary table another derived view we manage on xhibit (this is to replace the crest.disposal table which does not exist in xhibit).,,,,,,,,
Also worth noting that in the note about bw receipts we noted that current methodology adds defendant bw counts to case counts. As far as I remember this is not the case for disposals. WORTH CHECKING THOUGH!,,,,,,,,
In addtion to this we are going to proxy the disposal counts we are not going to reintroduce the full publication SQL as we could dedicate a notebook to that code itself. I have uploaded a write up on the full publication code disposals for reference it can be found at: s3://alpha-xhibit-comparisons/docs/defining_a_case_disposal_date.docx.,,,,,,,,
In [25]:,,,,,,,,
"print_sql_as_markdown(""sql/disposals/xhibit-bw-disposals.sql"")",,,,,,,,
Out[25]:,,,,,,,,
WITH bw AS (,,,,,,,,
"    SELECT case_id, min(outcome_date) AS outcome_date",,,,,,,,
    FROM xhibit_v1.disposal_summary,,,,,,,,
    WHERE year(outcome_date) <= 2017 AND year(outcome_date) > 2011,,,,,,,,
"    AND disposal_code IN('BWBAILN', 'BWBAILB', 'BWSUMN', 'BWSUMB')",,,,,,,,
    GROUP BY case_id,,,,,,,,
"),",,,,,,,,
rt AS (,,,,,,,,
"  SELECT ff.receipt_type_desc, bw.outcome_date",,,,,,,,
  FROM xhibit_v1.defendant_summary as ff,,,,,,,,
  INNER JOIN bw,,,,,,,,
  ON ff.case_id = bw.case_id,,,,,,,,
  WHERE ff.single_case_flag,,,,,,,,
),,,,,,,,
"SELECT year(outcome_date) as year, quarter(outcome_date) as quarter, receipt_type_desc, count(*) as n",,,,,,,,
FROM rt,,,,,,,,
"GROUP BY year(outcome_date), quarter(outcome_date), receipt_type_desc",,,,,,,,
I've altered the code very slightly to only count the min outcome date within the time period - this will have very little effect on the actual numbers and would likely only affect a small number of cases at the very beginning of the series.,,,,,,,,
In [79]:,,,,,,,,
"print_sql_as_markdown(""sql/disposals/xhibit-bw-disposals-altered.sql"")",,,,,,,,
Out[79]:,,,,,,,,
WITH bw AS (,,,,,,,,
"    SELECT case_id, min(outcome_date) AS outcome_date",,,,,,,,
    FROM xhibit_der_dev.disposal_summary,,,,,,,,
"    WHERE mojap_snapshot_date = date '2020-02-12' and disposal_code IN('BWBAILN', 'BWBAILB', 'BWSUMN', 'BWSUMB')",,,,,,,,
    GROUP BY case_id,,,,,,,,
"),                                               ",,,,,,,,
rt AS (,,,,,,,,
"  SELECT ff.receipt_type_desc, bw.outcome_date",,,,,,,,
  FROM xhibit_der_dev.defendant_summary as ff,,,,,,,,
  INNER JOIN bw,,,,,,,,
  ON ff.case_id = bw.case_id,,,,,,,,
  WHERE year(outcome_date) <= 2020 AND year(outcome_date) > 2011 and mojap_snapshot_date = date '2020-02-12' and ff.single_case_flag and case_type <> 'A',,,,,,,,
)                                                  ,,,,,,,,
"SELECT year(outcome_date) as year, quarter(outcome_date) as quarter, receipt_type_desc, count(*) as n",,,,,,,,
FROM rt,,,,,,,,
"GROUP BY year(outcome_date), quarter(outcome_date), receipt_type_desc",,,,,,,,
In [99]:,,,,,,,,
"x_bw_disp_sql = get_sql(""sql/disposals/xhibit-bw-disposals-altered.sql"")",,,,,,,,
x_bw_disp = df_from_sql(x_bw_disp_sql),,,,,,,,
x_bw_disp.head(),,,,,,,,
Out[99]:,,,,,,,,
,year,quarter,receipt_type_desc,n,,,,
0,2012,2,sent,353,,,,
1,2012,2,ind,175,,,,
2,2014,2,tew,642,,,,
3,2018,1,ind,289,,,,
4,2018,1,sent,636,,,,
In [100]:,,,,,,,,
"x_disp_plus_bw = pd.merge(x_disp, x_bw_disp, how='outer', on=['year', 'quarter', 'receipt_type_desc'])",,,,,,,,
"x_disp_plus_bw = x_disp_plus_bw.rename(columns={'n_x': 'x_n', 'n_y': 'bw_n'}).fillna(0)",,,,,,,,
x_disp_plus_bw['x_n'] = x_disp_plus_bw['x_n'].astype(int),,,,,,,,
x_disp_plus_bw['bw_n'] = x_disp_plus_bw['bw_n'].astype(int),,,,,,,,
x_disp_plus_bw['n'] = x_disp_plus_bw['x_n'] + x_disp_plus_bw['bw_n'],,,,,,,,
"x_disp_plus_bw = x_disp_plus_bw.drop(['x_n', 'bw_n'], axis=1)",,,,,,,,
"disposals2 = pd.concat([p_disposals, x_disp_plus_bw, x_disp_ccsq], sort=True)",,,,,,,,
"multi_line(disposals2, x='year_qtr:O', y='sum(n)', colour = 'source:N', title='disposals xhibit vs published (accounting for bw - only)')",,,,,,,,
Out[100]:,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
Let's measure the % differences from pub receipts to xhibit_flatfile + bws,,,,,,,,
In [101]:,,,,,,,,
"disp_comp = disposals2.groupby(by=['year_qtr','source']).sum().reset_index()",,,,,,,,
"disp_comp = disp_comp.set_index(['year_qtr','source']).unstack()",,,,,,,,
disp_comp = disp_comp['n'].reset_index(),,,,,,,,
# Filter out first quarter of 2012 as data is missing,,,,,,,,
disp_comp = disp_comp[disp_comp['year_qtr'] != '2012-1'],,,,,,,,
disp_comp['p_diff'] = (disp_comp['ff_xhibit'] - disp_comp['ccsq_xhibit'])/disp_comp['ccsq_xhibit'],,,,,,,,
alt.Chart(disp_comp).mark_bar().encode(,,,,,,,,
"    x='year_qtr',",,,,,,,,
"    y=alt.Y('p_diff:Q', axis=alt.Axis(format='%')),",,,,,,,,
    color=alt.condition(,,,,,,,,
"        abs(alt.datum.p_diff) <= 0.02,",,,,,,,,
"        alt.value(""steelblue""),  # The positive color",,,,,,,,
"        alt.value(""red"")  # The negative color",,,,,,,,
"    ),",,,,,,,,
"    tooltip=['p_diff', 'year_qtr']",,,,,,,,
").properties(width=600, title='Percentage difference xhibit vs crest disposals')",,,,,,,,
Out[101]:,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
transferred out disposals,,,,,,,,
In the published measures we also filter out transferred out cases (as they are dealt minused from receipts). So to get a better estimate we need to filter out transferred out cases from our defendant_summary counts.,,,,,,,,
As noted before most transferred out dates are missing because they only exist for the migrated courts but to be accurate we will remove them from the differences above.,,,,,,,,
The SQL below calculates the total number of disposals (minus transferred out) + bench warrant disposals to see what the difference is between that and the published figures. So it is a bit more involved.,,,,,,,,
In [29]:,,,,,,,,
"print_sql_as_markdown(""sql/disposals/xhibit-bw-no-trans-disposals.sql"")",,,,,,,,
Out[29]:,,,,,,,,
WITH bw AS (,,,,,,,,
"    SELECT case_id, min(outcome_date) AS outcome_date",,,,,,,,
    FROM xhibit_v1.disposal_summary,,,,,,,,
    WHERE year(outcome_date) <= 2017 AND year(outcome_date) > 2011,,,,,,,,
"    AND disposal_code IN('BWBAILN', 'BWBAILB', 'BWSUMN', 'BWSUMB')",,,,,,,,
    GROUP BY case_id,,,,,,,,
"),",,,,,,,,
bw_disps AS (,,,,,,,,
"  SELECT year(bw.outcome_date) as y, quarter(bw.outcome_date) as q, receipt_type_desc, count(*) as n",,,,,,,,
  FROM xhibit_v1.defendant_summary as ff,,,,,,,,
  INNER JOIN bw,,,,,,,,
  ON ff.case_id = bw.case_id,,,,,,,,
  WHERE ff.single_case_flag and (ff.disposal_type <> 'transferred_out' OR ff.disposal_type IS NULL),,,,,,,,
"  GROUP BY year(bw.outcome_date), quarter(bw.outcome_date), receipt_type_desc",,,,,,,,
"),",,,,,,,,
disps AS (,,,,,,,,
"  SELECT year(disposal_date) as y, quarter(disposal_date) as q, receipt_type_desc, count(*) as n",,,,,,,,
  FROM xhibit_v1.defendant_summary,,,,,,,,
  WHERE single_case_flag and (disposal_type <> 'transferred_out' OR disposal_type IS NULL),,,,,,,,
  AND year(disposal_date) <= 2017 AND year(disposal_date) > 2011,,,,,,,,
"  GROUP BY year(disposal_date), quarter(disposal_date), receipt_type_desc",,,,,,,,
),,,,,,,,
"SELECT disps.y as year,",,,,,,,,
"disps.q as quarter,",,,,,,,,
"disps.receipt_type_desc,",,,,,,,,
"(COALESCE(disps.n, 0) + COALESCE(bw_disps.n, 0)) as n",,,,,,,,
FROM disps,,,,,,,,
LEFT JOIN bw_disps,,,,,,,,
ON disps.y = bw_disps.y AND disps.q = bw_disps.q,,,,,,,,
AND disps.receipt_type_desc = bw_disps.receipt_type_desc,,,,,,,,
In [102]:,,,,,,,,
"print_sql_as_markdown(""sql/disposals/xhibit-bw-no-trans-disposals-altered.sql"")",,,,,,,,
Out[102]:,,,,,,,,
WITH bw AS (,,,,,,,,
"    SELECT case_id, min(outcome_date) AS outcome_date",,,,,,,,
    FROM xhibit_der_dev.disposal_summary,,,,,,,,
"    WHERE mojap_snapshot_date = date '2020-02-12' and disposal_code IN('BWBAILN', 'BWBAILB', 'BWSUMN', 'BWSUMB')",,,,,,,,
    GROUP BY case_id,,,,,,,,
"), ",,,,,,,,
bw_disps AS (,,,,,,,,
"  SELECT year(bw.outcome_date) as year, quarter(bw.outcome_date) as quarter, ff.receipt_type_desc, count(*) as n",,,,,,,,
  FROM xhibit_der_dev.defendant_summary as ff,,,,,,,,
  INNER JOIN bw,,,,,,,,
  ON ff.case_id = bw.case_id,,,,,,,,
  WHERE year(outcome_date) <= 2020 AND year(outcome_date) > 2011 and mojap_snapshot_date = date '2020-02-12' and ff.single_case_flag and case_type <> 'A' and (ff.disposal_type <> 'transferred_out' OR ff.disposal_type IS NULL),,,,,,,,
"  GROUP BY year(bw.outcome_date), quarter(bw.outcome_date), receipt_type_desc",,,,,,,,
"),   ",,,,,,,,
disps AS (,,,,,,,,
"  SELECT year(case_disposal_date) as year, quarter(case_disposal_date) as quarter, receipt_type_desc, count(*) as n",,,,,,,,
  FROM xhibit_der_dev.defendant_summary,,,,,,,,
  WHERE single_case_flag and (disposal_type <> 'transferred_out' OR disposal_type IS NULL) and mojap_snapshot_date = date '2020-02-12',,,,,,,,
"  GROUP BY year(case_disposal_date), quarter(case_disposal_date), receipt_type_desc",,,,,,,,
),,,,,,,,
"SELECT disps.year, disps.quarter, disps.receipt_type_desc, (COALESCE(disps.n, 0) + COALESCE(bw_disps.n, 0)) as n",,,,,,,,
FROM disps,,,,,,,,
LEFT JOIN bw_disps,,,,,,,,
ON disps.year = bw_disps.year AND disps.quarter = bw_disps.quarter,,,,,,,,
AND disps.receipt_type_desc = bw_disps.receipt_type_desc,,,,,,,,
Where disps.year > 2011 and disps.year < 2020,,,,,,,,
In [103]:,,,,,,,,
"x_all_disp_sql = get_sql(""sql/disposals/xhibit-bw-no-trans-disposals-altered.sql"")",,,,,,,,
x_all_disp = df_from_sql(x_all_disp_sql),,,,,,,,
"x_all_disp['year_qtr'] = x_all_disp[['year', 'quarter']].apply(lambda x: str(x[0]) + '-' + str(x[1]), axis=1)",,,,,,,,
x_all_disp['source'] = 'ff_xhibit',,,,,,,,
x_all_disp.head(),,,,,,,,
Out[103]:,,,,,,,,
,year,quarter,receipt_type_desc,n,year_qtr,source,,
0,2016,3,app,2749,2016-3,ff_xhibit,,
1,2017,4,app,2442,2017-4,ff_xhibit,,
2,2018,1,sent,8423,2018-1,ff_xhibit,,
3,2013,1,app,2885,2013-1,ff_xhibit,,
4,2013,4,app,2850,2013-4,ff_xhibit,,
In [104]:,,,,,,,,
"disposals3 = pd.concat([p_disposals, x_all_disp, x_disp_ccsq], sort=True)",,,,,,,,
disposals3['n'] = disposals3['n'].astype(int),,,,,,,,
"multi_line(disposals3, x='year_qtr:O', y='sum(n)', colour = 'source:N', title='disposals xhibit vs published (accounting for trans_out and bws)')",,,,,,,,
Out[104]:,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
In [105]:,,,,,,,,
"disp_comp2 = disposals3.groupby(by=['year_qtr','source']).sum().reset_index()",,,,,,,,
"disp_comp2 = disp_comp2.set_index(['year_qtr','source']).unstack()",,,,,,,,
disp_comp2 = disp_comp2['n'].reset_index(),,,,,,,,
# Filter out first quarter of 2012 as data is missing,,,,,,,,
disp_comp2 = disp_comp2[disp_comp2['year_qtr'] != '2012-1'],,,,,,,,
disp_comp2['p_diff'] = (disp_comp2['ff_xhibit'] - disp_comp2['ccsq_xhibit'])/disp_comp2['ccsq_xhibit'],,,,,,,,
alt.Chart(disp_comp2).mark_bar().encode(,,,,,,,,
"    x='year_qtr',",,,,,,,,
"    y=alt.Y('p_diff:Q', axis=alt.Axis(format='%')),",,,,,,,,
    color=alt.condition(,,,,,,,,
"        abs(alt.datum.p_diff) <= 0.02,",,,,,,,,
"        alt.value(""steelblue""),  # The positive color",,,,,,,,
"        alt.value(""red"")  # The negative color",,,,,,,,
"    ),",,,,,,,,
"    tooltip=['p_diff', 'year_qtr']",,,,,,,,
").properties(width=600, title='Percentage difference xhibit vs crest disposals')",,,,,,,,
Out[105]:,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
Below we do further breakdowns based on disposal type for reference:,,,,,,,,
(Note we exclude 2012-1 to make the plots axis better),,,,,,,,
In [111]:,,,,,,,,
"disp_comp_all2 = disposals2.groupby(by=['year_qtr','receipt_type_desc','source']).sum().reset_index()",,,,,,,,
"disp_comp_all2 = disp_comp_all2.set_index(['year_qtr','receipt_type_desc','source']).unstack()",,,,,,,,
disp_comp_all2 = disp_comp_all2['n'].reset_index(),,,,,,,,
# Filter out first quarter of 2012 as data is missing,,,,,,,,
disp_comp_all2 = disp_comp_all2[disp_comp_all2['year_qtr'] != '2012-1'],,,,,,,,
disp_comp_all2['p_diff'] = (disp_comp_all2['ff_xhibit'] - disp_comp_all2['ccsq_xhibit'])/disp_comp_all2['ccsq_xhibit'],,,,,,,,
In [112]:,,,,,,,,
def get_disposals_line_and_bar(cat):,,,,,,,,
    df1 = disposals2[(disposals2['receipt_type_desc'] == cat) & (disposals2['year_qtr'] != '2012-1')],,,,,,,,
"    df1.drop(['year','quarter', 'disposal_type'], axis=1)",,,,,,,,
    df2 = disp_comp_all2[(disp_comp_all2['receipt_type_desc'] == cat) & (disp_comp_all2['year_qtr'] != '2012-1')],,,,,,,,
"    ml = multi_line(df1, x='year_qtr:O', y='sum(n)', colour = 'source:N')",,,,,,,,
    ,,,,,,,,
    bar = alt.Chart(df2).mark_bar().encode(,,,,,,,,
"    x='year_qtr',",,,,,,,,
"    y=alt.Y('p_diff:Q', axis=alt.Axis(format='%')),",,,,,,,,
    color=alt.condition(,,,,,,,,
"        abs(alt.datum.p_diff) <= 0.02,",,,,,,,,
"        alt.value(""steelblue""),  # The positive color",,,,,,,,
"        alt.value(""red"")  # The negative color",,,,,,,,
"        ),",,,,,,,,
"        tooltip=['p_diff', 'year_qtr', 'receipt_type_desc']",,,,,,,,
    ).properties(width=600),,,,,,,,
    ,,,,,,,,
    return ml & bar,,,,,,,,
"for r in ['ind', 'tew', 'sent', 'app']:",,,,,,,,
display(Markdown(f'**Published vs Xhibit Disposals (receipt_type_desc: {r})**')),,,,,,,,
    display(get_disposals_line_and_bar(r)),,,,,,,,
Published vs Xhibit Disposals (receipt_type_desc: ind),,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
Published vs Xhibit Disposals (receipt_type_desc: tew),,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
Published vs Xhibit Disposals (receipt_type_desc: sent),,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
Published vs Xhibit Disposals (receipt_type_desc: app),,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
"There seems to be more variation in disposals than receipts, but it is still not that much.",,,,,,,,
"The biggest change is in the trials data, where the ccsq_xhibit appears to display a similar trend but has a lag compared to both crest and the ff_xhibit.",,,,,,,,
OUTSTANDING,,,,,,,,
Karik has produced analysis to compare the affect that the change in disposal outcome date has on the flat file measure; this is available at: file:///C:/Users/tsg77t/AppData/Local/Temp/outstandings_update.html,,,,,,,,
I will not reproduce this analysis but focuss on the new measure and examine the no_action assumption on this data.,,,,,,,,
Set up the code to pull off the new version of the ff xhibit os data. Again i will make the slight change to classify the bw data before we class cases as no_action.,,,,,,,,
"Check: Karik last time at the CTX meeting you mentioned some analyisis that looked at why you thought this was not appropriate, could you have a look, as i can't seem to understand why?",,,,,,,,
In [4]:,,,,,,,,
# Changes,,,,,,,,
# - withdrawn = N,,,,,,,,
# - bw_end_date has to occur after OS date,,,,,,,,
# - use latest hearing as proxy for no hearing vs flatfile. Note this gives a different measure of no hearing. It is now no hearing at time of OS,,,,,,,,
"def get_new_os_sql(db_date, os_date, db_name):",,,,,,,,
"    """"""",,,,,,,,
    For all case types not just Trial cases,,,,,,,,
"    """"""",,,,,,,,
    ,,,,,,,,
"    sql = f""""""",,,,,,,,
    WITH h AS (,,,,,,,,
"    SELECT case_id, MAX(hearing_start_date) as latest_hearing",,,,,,,,
    FROM {db_name}.def_hearing_summary,,,,,,,,
    WHERE valid_hearing and hearing_start_date <= date '{os_date}',,,,,,,,
    AND mojap_snapshot_date = date '{db_date}',,,,,,,,
    GROUP BY case_id,,,,,,,,
"    ),",,,,,,,,
    b AS (,,,,,,,,
"        SELECT defendant_on_case_id, outstanding_bw",,,,,,,,
        FROM,,,,,,,,
        (,,,,,,,,
"            SELECT defendant_on_case_id,",,,,,,,,
"            row_number() OVER (PARTITION BY defendant_on_case_id ORDER BY COALESCE(bw_issue_date, date '1980-01-01') DESC) AS rn,",,,,,,,,
"            CASE WHEN COALESCE(bw_end_date, date '2999-01-01') > date '{os_date}' THEN 1 ELSE 0 END AS outstanding_bw",,,,,,,,
            FROM xhibit_v1.bw_history,,,,,,,,
"            WHERE bw_issue_date IS NOT NULL AND COALESCE(bw_issue_date, date '1980-01-01') <= date '{os_date}' and mis_record_type <> 'D'",,,,,,,,
            and mojap_start_datetime <= date '{db_date}' and mojap_end_datetime > date '{db_date}'  ,,,,,,,,
"            and COALESCE(obs_ind, 'N') <> 'Y' and COALESCE(withdrawn, 'N') = 'N' ",,,,,,,,
        ),,,,,,,,
        WHERE rn = 1,,,,,,,,
"    ),",,,,,,,,
    os AS (,,,,,,,,
"    SELECT d.case_id, d.single_case_flag, d.receipt_date, d.court_name, d.receipt_type_desc, d.remand_on_committal, d.mojap_snapshot_date,",,,,,,,,
    (,,,,,,,,
      CASE,,,,,,,,
      WHEN d.offence_ho_group_msd IS NULL THEN '00: Unknown',,,,,,,,
"      ELSE CONCAT(d.offence_ho_group_mso, ': ', d.offence_ho_group_desc_mso)",,,,,,,,
      END,,,,,,,,
"    ) AS offence_group_mso,",,,,,,,,
"    MAX(CASE WHEN h.latest_hearing IS NULL THEN 1 ELSE 0 END) OVER (PARTITION BY d.case_id) AS case_no_hearing,",,,,,,,,
"    MAX(CASE WHEN b.outstanding_bw IS NULL THEN 0 ELSE b.outstanding_bw END) OVER (PARTITION BY d.case_id) AS case_outstanding_bw,",,,,,,,,
"    (date_diff('day', COALESCE(h.latest_hearing, d.receipt_date), date '{os_date}') >= 365) AS no_action",,,,,,,,
    FROM {db_name}.defendant_summary as d,,,,,,,,
    LEFT JOIN h,,,,,,,,
    ON h.case_id = d.case_id,,,,,,,,
    LEFT JOIN b,,,,,,,,
    ON b.defendant_on_case_id = d.defendant_on_case_id,,,,,,,,
    WHERE (d.case_disposal_date > date '{os_date}' OR d.case_disposal_date IS NULL) AND d.receipt_date <= date '{os_date}',,,,,,,,
    AND mojap_snapshot_date = date '{db_date}',,,,,,,,
"    ),",,,,,,,,
    final AS (,,,,,,,,
"    SELECT case_id, receipt_type_desc, remand_on_committal, offence_group_mso, ",,,,,,,,
"    date_diff('day', receipt_date, date '{os_date}') as age_days,",,,,,,,,
    (,,,,,,,,
      CASE,,,,,,,,
      WHEN case_outstanding_bw = 1 THEN 'outstanding_bw',,,,,,,,
      WHEN no_action THEN 'no_action' ,,,,,,,,
      WHEN case_no_hearing = 1 THEN 'no_hearing',,,,,,,,
      ELSE 'outstanding' END,,,,,,,,
"    ) as outstanding_reason,",,,,,,,,
"    '{os_date}' as os_date,",,,,,,,,
    mojap_snapshot_date,,,,,,,,
    FROM os,,,,,,,,
    WHERE single_case_flag,,,,,,,,
    AND NOT (court_name LIKE '%(CLOSED COURT)' OR court_name IS NULL),,,,,,,,
    AND year(receipt_date) >= 2012,,,,,,,,
    ),,,,,,,,
"    SELECT os_date, outstanding_reason, receipt_type_desc, count(*) as n",,,,,,,,
    FROM final,,,,,,,,
"    GROUP BY os_date, outstanding_reason, receipt_type_desc",,,,,,,,
"    """"""",,,,,,,,
    ,,,,,,,,
    return sql,,,,,,,,
In [5]:,,,,,,,,
"def get_os_dates(start_date, end_date):",,,,,,,,
"    """"""",,,,,,,,
    Returns array of os dates for each month. Start and end dates should be first of the month.,,,,,,,,
    First date in array is the last day of the month of the start_date. Last date is array is the,,,,,,,,
    day before the end_date.,,,,,,,,
    ,,,,,,,,
    Example:,,,,,,,,
"    get_os_dates(""2018-01-01"", ""2018-03-01"") # returns [""2018-01-30"", ""2018-02-28""]",,,,,,,,
"    """"""",,,,,,,,
    next_date = start_date,,,,,,,,
    os_dates = [],,,,,,,,
    while True:,,,,,,,,
        if next_date == end_date:,,,,,,,,
            break,,,,,,,,
"        next_date_dt = datetime.strptime(next_date, ""%Y-%m-%d"") + relativedelta(months=1)",,,,,,,,
"        next_date = next_date_dt.strftime(""%Y-%m-%d"")",,,,,,,,
        os_date_dt = next_date_dt - relativedelta(days=1),,,,,,,,
"        os_dates.append(os_date_dt.strftime(""%Y-%m-%d""))",,,,,,,,
    ,,,,,,,,
    return os_dates,,,,,,,,
In [6]:,,,,,,,,
from datetime import datetime,,,,,,,,
from dateutil.relativedelta import relativedelta,,,,,,,,
import pydbtools as pydb,,,,,,,,
import pandas as pd,,,,,,,,
## db_names can be xhibit_der_v1 or xhibit_der_dev,,,,,,,,
"os_dates = [o for o in get_os_dates(""2013-01-01"", ""2020-01-01"") if o.split(""-"")[1] in [""03"", ""06"", ""09"", ""12""]]",,,,,,,,
all_new = None,,,,,,,,
for od in os_dates:,,,,,,,,
"    print(f""RUNNING: {od}"")",,,,,,,,
"new = pydb.read_sql(get_new_os_sql(""2020-02-12"", od, ""xhibit_der_dev""), cols_as_str=True)",,,,,,,,
    ,,,,,,,,
"    all_new = pd.concat([all_new, new])",,,,,,,,
RUNNING: 2013-03-31,,,,,,,,
RUNNING: 2013-06-30,,,,,,,,
RUNNING: 2013-09-30,,,,,,,,
RUNNING: 2013-12-31,,,,,,,,
RUNNING: 2014-03-31,,,,,,,,
RUNNING: 2014-06-30,,,,,,,,
RUNNING: 2014-09-30,,,,,,,,
RUNNING: 2014-12-31,,,,,,,,
RUNNING: 2015-03-31,,,,,,,,
RUNNING: 2015-06-30,,,,,,,,
RUNNING: 2015-09-30,,,,,,,,
RUNNING: 2015-12-31,,,,,,,,
RUNNING: 2016-03-31,,,,,,,,
RUNNING: 2016-06-30,,,,,,,,
RUNNING: 2016-09-30,,,,,,,,
RUNNING: 2016-12-31,,,,,,,,
RUNNING: 2017-03-31,,,,,,,,
RUNNING: 2017-06-30,,,,,,,,
RUNNING: 2017-09-30,,,,,,,,
RUNNING: 2017-12-31,,,,,,,,
RUNNING: 2018-03-31,,,,,,,,
RUNNING: 2018-06-30,,,,,,,,
RUNNING: 2018-09-30,,,,,,,,
RUNNING: 2018-12-31,,,,,,,,
RUNNING: 2019-03-31,,,,,,,,
RUNNING: 2019-06-30,,,,,,,,
RUNNING: 2019-09-30,,,,,,,,
RUNNING: 2019-12-31,,,,,,,,
In [7]:,,,,,,,,
all_new.head(),,,,,,,,
Out[7]:,,,,,,,,
,os_date,outstanding_reason,receipt_type_desc,n,,,,
0,31/03/2013,outstanding_bw,tew,251,,,,
1,31/03/2013,no_action,app,7,,,,
2,31/03/2013,outstanding,ind,11552,,,,
3,31/03/2013,outstanding,sent,1811,,,,
4,31/03/2013,outstanding_bw,sent,390,,,,
Lets plot the xhibit OS data to have a look at what we have.,,,,,,,,
In [11]:,,,,,,,,
"all_new[""os_type""] = ""new""",,,,,,,,
"all_new[""n""] = all_new[""n""].astype(int)",,,,,,,,
all_new['os_reason'] = all_new['outstanding_reason'].map({,,,,,,,,
"    ""no_hearing"": ""03: No hearing"",",,,,,,,,
"    ""outstanding_bw"": ""02: OS BW"",",,,,,,,,
"    ""no_action"": ""01: No hearing after 365 days"",",,,,,,,,
"    ""outstanding"": ""04: Outstanding"",",,,,,,,,
}),,,,,,,,
alt.Chart(all_new).mark_bar().encode(,,,,,,,,
"    x='os_date:O',",,,,,,,,
"    y='sum(n):Q',",,,,,,,,
"    color='os_reason:N',",,,,,,,,
"    tooltip=[""os_type"", ""sum(n)"", ""outstanding_reason"", ""os_date""]",,,,,,,,
),,,,,,,,
Out[11]:,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
Lets look at the number of no hearing after 365 days and see what happens to these figures over time.,,,,,,,,
In [12]:,,,,,,,,
"alt.Chart(all_new[all_new[""outstanding_reason""] == ""no_action""]).mark_bar().encode(",,,,,,,,
"    x='os_date:N',",,,,,,,,
"    y='sum(n):Q',",,,,,,,,
"    color='os_reason:N',",,,,,,,,
"    tooltip=[""os_type"", ""sum(n)"", ""os_reason"", ""os_date""]",,,,,,,,
").properties(width=600, title='Cases classed as no_action')",,,,,,,,
Out[12]:,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
Once we have taken into account of the BW we can see that the figures that we exclude due to the 365 assumption are betweeen 751 and 383 since 2014.,,,,,,,,
If these truely were 'zombie' cases we would expect to only see an increase in these numbers and not the fall we are currently seeing since March 2018 (741).,,,,,,,,
To help look at this it may be useful to look at the age breakdown of these cases.,,,,,,,,
In [26]:,,,,,,,,
# Changes,,,,,,,,
# - withdrawn = N,,,,,,,,
# - bw_end_date has to occur after OS date,,,,,,,,
# - use latest hearing as proxy for no hearing vs flatfile. Note this gives a different measure of no hearing. It is now no hearing at time of OS,,,,,,,,
"def get_new_n_a_sql(db_date, os_date, db_name):",,,,,,,,
"    """"""",,,,,,,,
    For all case types not just Trial cases,,,,,,,,
"    """"""",,,,,,,,
    ,,,,,,,,
"    sql = f""""""",,,,,,,,
    WITH h AS (,,,,,,,,
"    SELECT case_id, MAX(hearing_start_date) as latest_hearing",,,,,,,,
    FROM {db_name}.def_hearing_summary,,,,,,,,
    WHERE valid_hearing and hearing_start_date <= date '{os_date}',,,,,,,,
    AND mojap_snapshot_date = date '{db_date}',,,,,,,,
    GROUP BY case_id,,,,,,,,
"    ),",,,,,,,,
    b AS (,,,,,,,,
"        SELECT defendant_on_case_id, outstanding_bw",,,,,,,,
        FROM,,,,,,,,
        (,,,,,,,,
"            SELECT defendant_on_case_id,",,,,,,,,
"            row_number() OVER (PARTITION BY defendant_on_case_id ORDER BY COALESCE(bw_issue_date, date '1980-01-01') DESC) AS rn,",,,,,,,,
"            CASE WHEN COALESCE(bw_end_date, date '2999-01-01') > date '{os_date}' THEN 1 ELSE 0 END AS outstanding_bw",,,,,,,,
            FROM xhibit_v1.bw_history,,,,,,,,
"            WHERE bw_issue_date IS NOT NULL AND COALESCE(bw_issue_date, date '1980-01-01') <= date '{os_date}' and mis_record_type <> 'D'",,,,,,,,
            and mojap_start_datetime <= date '{db_date}' and mojap_end_datetime > date '{db_date}'  ,,,,,,,,
"            and COALESCE(obs_ind, 'N') <> 'Y' and COALESCE(withdrawn, 'N') = 'N' ",,,,,,,,
        ),,,,,,,,
        WHERE rn = 1,,,,,,,,
"    ),",,,,,,,,
    os AS (,,,,,,,,
"    SELECT d.case_id, d.single_case_flag, d.receipt_date, d.court_name, d.receipt_type_desc, d.remand_on_committal, d.mojap_snapshot_date,",,,,,,,,
    (,,,,,,,,
      CASE,,,,,,,,
      WHEN d.offence_ho_group_msd IS NULL THEN '00: Unknown',,,,,,,,
"      ELSE CONCAT(d.offence_ho_group_mso, ': ', d.offence_ho_group_desc_mso)",,,,,,,,
      END,,,,,,,,
"    ) AS offence_group_mso,",,,,,,,,
"    MAX(CASE WHEN h.latest_hearing IS NULL THEN 1 ELSE 0 END) OVER (PARTITION BY d.case_id) AS case_no_hearing,",,,,,,,,
"    MAX(CASE WHEN b.outstanding_bw IS NULL THEN 0 ELSE b.outstanding_bw END) OVER (PARTITION BY d.case_id) AS case_outstanding_bw,",,,,,,,,
"    (date_diff('day', COALESCE(h.latest_hearing, d.receipt_date), date '{os_date}') >= 365) AS no_action,",,,,,,,,
"    date_diff('day', COALESCE(h.latest_hearing, d.receipt_date), date '{os_date}') as time_no_action",,,,,,,,
    FROM {db_name}.defendant_summary as d,,,,,,,,
    LEFT JOIN h,,,,,,,,
    ON h.case_id = d.case_id,,,,,,,,
    LEFT JOIN b,,,,,,,,
    ON b.defendant_on_case_id = d.defendant_on_case_id,,,,,,,,
    WHERE (d.case_disposal_date > date '{os_date}' OR d.case_disposal_date IS NULL) AND d.receipt_date <= date '{os_date}',,,,,,,,
    AND mojap_snapshot_date = date '{db_date}',,,,,,,,
"    ),",,,,,,,,
    final AS (,,,,,,,,
"    SELECT case_id, receipt_type_desc, remand_on_committal, offence_group_mso,",,,,,,,,
"    date_diff('day', receipt_date, date '{os_date}') as age_days,",,,,,,,,
    (,,,,,,,,
      CASE,,,,,,,,
      WHEN time_no_action <365 THEN '0. Had action within the year',,,,,,,,
      WHEN time_no_action <395 THEN '1. last action 12-13mths ago',,,,,,,,
      WHEN time_no_action <425 THEN '2. last action 13-14mths ago',,,,,,,,
      WHEN time_no_action <455 THEN '3. last action 14-15mths ago',,,,,,,,
      WHEN time_no_action <545 THEN '4. last action 15-18mths ago',,,,,,,,
      WHEN time_no_action <730 THEN '5. last action 18-24mths ago',,,,,,,,
      ELSE '6. last action more than 2yrs ago' END,,,,,,,,
"    ) as time_no_action_banded,",,,,,,,,
    (,,,,,,,,
      CASE,,,,,,,,
      WHEN case_outstanding_bw = 1 THEN 'outstanding_bw',,,,,,,,
      WHEN no_action THEN 'no_action' ,,,,,,,,
      WHEN case_no_hearing = 1 THEN 'no_hearing',,,,,,,,
      ELSE 'outstanding' END,,,,,,,,
"    ) as outstanding_reason,",,,,,,,,
"    '{os_date}' as os_date,",,,,,,,,
    mojap_snapshot_date,,,,,,,,
    FROM os,,,,,,,,
    WHERE single_case_flag,,,,,,,,
    AND NOT (court_name LIKE '%(CLOSED COURT)' OR court_name IS NULL),,,,,,,,
    AND year(receipt_date) >= 2012,,,,,,,,
    ),,,,,,,,
"    SELECT os_date, time_no_action_banded, count(*) as n",,,,,,,,
    FROM final,,,,,,,,
    WHERE outstanding_reason = 'no_action',,,,,,,,
"    GROUP BY os_date, time_no_action_banded",,,,,,,,
"    """"""",,,,,,,,
    ,,,,,,,,
    return sql,,,,,,,,
In [27]:,,,,,,,,
from datetime import datetime,,,,,,,,
from dateutil.relativedelta import relativedelta,,,,,,,,
import pydbtools as pydb,,,,,,,,
import pandas as pd,,,,,,,,
## db_names can be xhibit_der_v1 or xhibit_der_dev,,,,,,,,
## HERE I RUN old OS measure (with v1 db) again new OS measure (with dev db) for each quarter from 2013 - 2019,,,,,,,,
"os_dates = [o for o in get_os_dates(""2013-01-01"", ""2020-01-01"") if o.split(""-"")[1] in [""03"", ""06"", ""09"", ""12""]]",,,,,,,,
all_new_n_a = None,,,,,,,,
for od in os_dates:,,,,,,,,
"    print(f""RUNNING: {od}"")",,,,,,,,
"    new_n_a = pydb.read_sql(get_new_n_a_sql(""2020-02-12"", od, ""xhibit_der_dev""), cols_as_str=True)",,,,,,,,
    ,,,,,,,,
"    all_new_n_a = pd.concat([all_new_n_a, new_n_a])",,,,,,,,
RUNNING: 2013-03-31,,,,,,,,
RUNNING: 2013-06-30,,,,,,,,
RUNNING: 2013-09-30,,,,,,,,
RUNNING: 2013-12-31,,,,,,,,
RUNNING: 2014-03-31,,,,,,,,
RUNNING: 2014-06-30,,,,,,,,
RUNNING: 2014-09-30,,,,,,,,
RUNNING: 2014-12-31,,,,,,,,
RUNNING: 2015-03-31,,,,,,,,
RUNNING: 2015-06-30,,,,,,,,
RUNNING: 2015-09-30,,,,,,,,
RUNNING: 2015-12-31,,,,,,,,
RUNNING: 2016-03-31,,,,,,,,
RUNNING: 2016-06-30,,,,,,,,
RUNNING: 2016-09-30,,,,,,,,
RUNNING: 2016-12-31,,,,,,,,
RUNNING: 2017-03-31,,,,,,,,
RUNNING: 2017-06-30,,,,,,,,
RUNNING: 2017-09-30,,,,,,,,
RUNNING: 2017-12-31,,,,,,,,
RUNNING: 2018-03-31,,,,,,,,
RUNNING: 2018-06-30,,,,,,,,
RUNNING: 2018-09-30,,,,,,,,
RUNNING: 2018-12-31,,,,,,,,
RUNNING: 2019-03-31,,,,,,,,
RUNNING: 2019-06-30,,,,,,,,
RUNNING: 2019-09-30,,,,,,,,
RUNNING: 2019-12-31,,,,,,,,
In [28]:,,,,,,,,
all_new_n_a.head(),,,,,,,,
Out[28]:,,,,,,,,
,os_date,time_no_action_banded,n,,,,,
0,31/03/2013,4. last action 15-18mths ago,1,,,,,
1,31/03/2013,3. last action 14-15mths ago,8,,,,,
2,31/03/2013,2. last action 13-14mths ago,39,,,,,
3,31/03/2013,1. last action 12-13mths ago,25,,,,,
0,30/06/2013,4. last action 15-18mths ago,52,,,,,
In [29]:,,,,,,,,
"all_new_n_a[""os_type""] = ""new""",,,,,,,,
"all_new_n_a[""n""] = all_new_n_a[""n""].astype(int)",,,,,,,,
alt.Chart(all_new_n_a).mark_bar().encode(,,,,,,,,
"    x='os_date:N',",,,,,,,,
"    y='sum(n):Q',",,,,,,,,
"    color='time_no_action_banded:N',",,,,,,,,
"    tooltip=[""os_type"", ""sum(n)"", ""time_no_action_banded"", ""os_date""]",,,,,,,,
").properties(width=600, title='Age profile of no_action_cases from the 1 year cut off')",,,,,,,,
Out[29]:,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
"Again, even the group of very oldest cases on the system (those which hae had no action in more than 2 years) are not growing, but have decreased in volume in teh most recent period.",,,,,,,,
Lets compare the outstanding counts from publishd and xhibit,,,,,,,,
In [30]:,,,,,,,,
# Filter out bw_os,,,,,,,,
all_new['source'] = 'ff_xhibit_exc_bw',,,,,,,,
"ff_xhibit_exc_bw = all_new[all_new[""outstanding_reason""] != ""outstanding_bw""]",,,,,,,,
ff_xhibit_exc_bw.head(),,,,,,,,
Out[30]:,,,,,,,,
,os_date,outstanding_reason,receipt_type_desc,n,os_type,os_reason,source,
1,31/03/2013,no_action,app,7,new,01: No hearing after 365 days,ff_xhibit_exc_bw,
2,31/03/2013,outstanding,ind,11552,new,04: Outstanding,ff_xhibit_exc_bw,
3,31/03/2013,outstanding,sent,1811,new,04: Outstanding,ff_xhibit_exc_bw,
6,31/03/2013,no_hearing,sent,2835,new,03: No hearing,ff_xhibit_exc_bw,
7,31/03/2013,outstanding,tew,11706,new,04: Outstanding,ff_xhibit_exc_bw,
In [31]:,,,,,,,,
# Filter out no_action too,,,,,,,,
all_new['source'] = 'ff_xhibit_exc_bw_na',,,,,,,,
"ff_xhibit_exc_bw_na = all_new[all_new[""outstanding_reason""] != ""outstanding_bw""]",,,,,,,,
"ff_xhibit_exc_bw_na = ff_xhibit_exc_bw_na[ff_xhibit_exc_bw_na[""outstanding_reason""] != ""no_action""]",,,,,,,,
ff_xhibit_exc_bw_na.head(),,,,,,,,
Out[31]:,,,,,,,,
,os_date,outstanding_reason,receipt_type_desc,n,os_type,os_reason,source,
2,31/03/2013,outstanding,ind,11552,new,04: Outstanding,ff_xhibit_exc_bw_na,
3,31/03/2013,outstanding,sent,1811,new,04: Outstanding,ff_xhibit_exc_bw_na,
6,31/03/2013,no_hearing,sent,2835,new,03: No hearing,ff_xhibit_exc_bw_na,
7,31/03/2013,outstanding,tew,11706,new,04: Outstanding,ff_xhibit_exc_bw_na,
8,31/03/2013,no_hearing,tew,4722,new,03: No hearing,ff_xhibit_exc_bw_na,
In [36]:,,,,,,,,
"outstanding = pd.concat([p_outstanding, h_outstanding, ff_xhibit_exc_bw, ff_xhibit_exc_bw_na], sort=True)",,,,,,,,
# Filter out first quarter of 2012 as data is missing,,,,,,,,
outstanding = outstanding[outstanding['os_date'] != '2012-03-31'],,,,,,,,
outstanding = outstanding[outstanding['os_date'] != '2012-06-30'],,,,,,,,
outstanding = outstanding[outstanding['os_date'] != '2012-09-30'],,,,,,,,
outstanding = outstanding[outstanding['os_date'] != '2012-12-31'],,,,,,,,
outstanding['n'] = outstanding['n'].astype(int),,,,,,,,
"multi_line(outstanding, x='os_date:O', y='sum(n)', colour = 'source:N', title='outstanding xhibit vs published')",,,,,,,,
Out[36]:,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
Let's have a look at how different the two FF exhibit methods are (exc BW only vs exc BW and no-action-cases) by comparing the percentage difference. (The volumes are the no action differences above so we know they range betweeen 751 and 383 since 2014.,,,,,,,,
In [45]:,,,,,,,,
"outstanding_comp = outstanding.groupby(by=['os_date','source']).sum().reset_index()",,,,,,,,
"outstanding_comp = outstanding_comp.set_index(['os_date','source']).unstack()",,,,,,,,
outstanding_comp = outstanding_comp['n'].reset_index(),,,,,,,,
outstanding_comp['p_diff'] = (outstanding_comp['ff_xhibit_exc_bw'] - outstanding_comp['ff_xhibit_exc_bw_na'])/outstanding_comp['ff_xhibit_exc_bw_na'],,,,,,,,
alt.Chart(outstanding_comp).mark_bar().encode(,,,,,,,,
"    x='os_date',",,,,,,,,
"    y=alt.Y('p_diff:Q', axis=alt.Axis(format='%')),",,,,,,,,
    color=alt.condition(,,,,,,,,
"        abs(alt.datum.p_diff) <= 0.02,",,,,,,,,
"        alt.value(""steelblue""),  # The positive color",,,,,,,,
"        alt.value(""red"")  # The negative color",,,,,,,,
"    ),",,,,,,,,
"    tooltip=['p_diff', 'os_date']",,,,,,,,
").properties(width=600, title='Percentage difference xhibit exc bw only vs xhibit exc bw and no action')",,,,,,,,
Out[45]:,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
It's only in 2 quarters where there is a difference of more than 2%.,,,,,,,,
Now we will look at the percentage differences between each measure.,,,,,,,,
In [38]:,,,,,,,,
outstanding_comp['p_diff'] = (outstanding_comp['ff_xhibit_exc_bw'] - outstanding_comp['publication_crest'])/outstanding_comp['publication_crest'],,,,,,,,
alt.Chart(outstanding_comp).mark_bar().encode(,,,,,,,,
"    x='os_date',",,,,,,,,
"    y=alt.Y('p_diff:Q', axis=alt.Axis(format='%')),",,,,,,,,
    color=alt.condition(,,,,,,,,
"        abs(alt.datum.p_diff) <= 0.02,",,,,,,,,
"        alt.value(""steelblue""),  # The positive color",,,,,,,,
"        alt.value(""red"")  # The negative color",,,,,,,,
"    ),",,,,,,,,
"    tooltip=['p_diff', 'os_date']",,,,,,,,
").properties(width=600, title='Percentage difference xhibit exc bw only vs crest outstanding cases')",,,,,,,,
Out[38]:,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
So when we compare the FF exhibit exc BW the match is realtively good - this is probably as we never used to exclude cases that had no action in a year so is he closest measure to how we used to measure it.,,,,,,,,
In [46]:,,,,,,,,
outstanding_comp['p_diff'] = (outstanding_comp['ff_xhibit_exc_bw_na'] - outstanding_comp['publication_crest'])/outstanding_comp['publication_crest'],,,,,,,,
alt.Chart(outstanding_comp).mark_bar().encode(,,,,,,,,
"    x='os_date',",,,,,,,,
"    y=alt.Y('p_diff:Q', axis=alt.Axis(format='%')),",,,,,,,,
    color=alt.condition(,,,,,,,,
"        abs(alt.datum.p_diff) <= 0.02,",,,,,,,,
"        alt.value(""steelblue""),  # The positive color",,,,,,,,
"        alt.value(""red"")  # The negative color",,,,,,,,
"    ),",,,,,,,,
"    tooltip=['p_diff', 'os_date']",,,,,,,,
").properties(width=600, title='Percentage difference xhibit exc bw and no action vs crest outstanding cases')",,,,,,,,
Out[46]:,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
So when we now exclude the no_action_cases from the OS measure the differences between this new stream and what we used to publish in Crest is more pronounced.,,,,,,,,
If we have a quick look at how the measure compares with published HMCTS outstanding.,,,,,,,,
In [48]:,,,,,,,,
outstanding_comp['p_diff'] = (outstanding_comp['ff_xhibit_exc_bw'] - outstanding_comp['hmcts_opt'])/outstanding_comp['hmcts_opt'],,,,,,,,
alt.Chart(outstanding_comp).mark_bar().encode(,,,,,,,,
"    x='os_date',",,,,,,,,
"    y=alt.Y('p_diff:Q', axis=alt.Axis(format='%')),",,,,,,,,
    color=alt.condition(,,,,,,,,
"        abs(alt.datum.p_diff) <= 0.02,",,,,,,,,
"        alt.value(""steelblue""),  # The positive color",,,,,,,,
"        alt.value(""red"")  # The negative color",,,,,,,,
"    ),",,,,,,,,
"    tooltip=['p_diff', 'os_date']",,,,,,,,
").properties(width=600, title='Percentage difference xhibit exc bw only vs hmcts_opt disposals')",,,,,,,,
Out[48]:,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
In [49]:,,,,,,,,
outstanding_comp['p_diff'] = (outstanding_comp['ff_xhibit_exc_bw_na'] - outstanding_comp['hmcts_opt'])/outstanding_comp['hmcts_opt'],,,,,,,,
alt.Chart(outstanding_comp).mark_bar().encode(,,,,,,,,
"    x='os_date',",,,,,,,,
"    y=alt.Y('p_diff:Q', axis=alt.Axis(format='%')),",,,,,,,,
    color=alt.condition(,,,,,,,,
"        abs(alt.datum.p_diff) <= 0.02,",,,,,,,,
"        alt.value(""steelblue""),  # The positive color",,,,,,,,
"        alt.value(""red"")  # The negative color",,,,,,,,
"    ),",,,,,,,,
"    tooltip=['p_diff', 'os_date']",,,,,,,,
").properties(width=600, title='Percentage difference xhibit exc bw and no action vs hmcts_opt outstanding cases')",,,,,,,,
Out[49]:,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
Here it matches more when the no_action_cases are also excluded - and ths is probably due to the methodology being more in line as HMCTS apply this exclusion.,,,,,,,,
Lets take a look at the split by casetype to reassure ourselves.,,,,,,,,
In [50]:,,,,,,,,
"outstanding_comp_rt = outstanding.groupby(by=['os_date','receipt_type_desc','source']).sum().reset_index()",,,,,,,,
# Filter out hmcts data as it has a slightly different split of receipts so can not be used in the comparison,,,,,,,,
outstanding_comp_rt = outstanding_comp_rt[outstanding_comp_rt['source'] != 'hmcts_opt'],,,,,,,,
"outstanding_comp_rt = outstanding_comp_rt.set_index(['os_date','receipt_type_desc','source']).unstack()",,,,,,,,
outstanding_comp_rt = outstanding_comp_rt['n'].reset_index(),,,,,,,,
# Filter out first quarter of 2012 as data is missing,,,,,,,,
outstanding_comp_rt = outstanding_comp_rt[outstanding_comp_rt['os_date'] != '2012-03-31'],,,,,,,,
outstanding_comp_rt = outstanding_comp_rt[outstanding_comp_rt['os_date'] != '2012-06-30'],,,,,,,,
outstanding_comp_rt = outstanding_comp_rt[outstanding_comp_rt['os_date'] != '2012-09-30'],,,,,,,,
outstanding_comp_rt = outstanding_comp_rt[outstanding_comp_rt['os_date'] != '2012-12-31'],,,,,,,,
outstanding_comp_rt['p_diff'] = (outstanding_comp_rt['ff_xhibit_exc_bw'] - outstanding_comp_rt['publication_crest'])/outstanding_comp_rt['publication_crest'],,,,,,,,
outstanding_comp_rt.head(),,,,,,,,
Out[50]:,,,,,,,,
source,os_date,receipt_type_desc,ff_xhibit_exc_bw,ff_xhibit_exc_bw_na,publication_crest,p_diff,,
0,31/03/2013,app,2620,2613,2714,-0.034635,,
1,31/03/2013,ind,14453,14438,15037,-0.038838,,
2,31/03/2013,sent,4679,4646,5141,-0.089866,,
3,31/03/2013,tew,16446,16428,17191,-0.043337,,
4,30/06/2013,app,2485,2466,2572,-0.033826,,
In [52]:,,,,,,,,
#Again remove HMCTS as the splits are different,,,,,,,,
outstanding_rt = outstanding[outstanding['source'] != 'hmcts_opt'],,,,,,,,
def get_os_line_and_bar(cat):,,,,,,,,
    os1 = outstanding_rt[(outstanding_rt['receipt_type_desc'] == cat)],,,,,,,,
"    os1.drop(['year','quarter', 'disposal_type','os_reason','os_type','outstanding_reason','year_qtr'], axis=1)",,,,,,,,
    os2 = outstanding_comp_rt[(outstanding_comp_rt['receipt_type_desc'] == cat)],,,,,,,,
    ,,,,,,,,
"    ml = multi_line(os1, x='os_date:O', y='sum(n)', colour = 'source:N')",,,,,,,,
    ,,,,,,,,
    bar = alt.Chart(os2).mark_bar().encode(,,,,,,,,
"    x='os_date:O',",,,,,,,,
"    y=alt.Y('p_diff:Q', axis=alt.Axis(format='%')),",,,,,,,,
    color=alt.condition(,,,,,,,,
"        abs(alt.datum.p_diff) <= 0.02,",,,,,,,,
"        alt.value(""steelblue""),  # The positive color",,,,,,,,
"        alt.value(""red"")  # The negative color",,,,,,,,
"        ),",,,,,,,,
"        tooltip=['p_diff', 'os_date', 'receipt_type_desc']",,,,,,,,
    ).properties(width=600),,,,,,,,
    ,,,,,,,,
    return ml & bar,,,,,,,,
"for r in ['ind', 'tew', 'sent', 'app']:",,,,,,,,
display(Markdown(f'**Published crest vs Xhibit outstanding exc BW (receipt_type_desc: {r})**')),,,,,,,,
    display(get_os_line_and_bar(r)),,,,,,,,
Published crest vs Xhibit outstanding exc BW (receipt_type_desc: ind),,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
Published crest vs Xhibit outstanding exc BW (receipt_type_desc: tew),,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
Published crest vs Xhibit outstanding exc BW (receipt_type_desc: sent),,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
Published crest vs Xhibit outstanding exc BW (receipt_type_desc: app),,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
,,,,,,,,
"Sent cases look like they divirge the most, and it would be good to have a closer look at these, however they are small in volume so have little affect on overall figures.",,,,,,,,
"In general the OS measure which only excludes BW figures look like a good match to previously published OS figures. There data from xhibit appears to have a slight undercount in very old data - I suspect that this is because we only include cases with a receipt date after 2011, it would be good to flex this criteria to an earlier date to see if we can get more of a complete back series which is not biased by this selection criteria.",,,,,,,,
Going forward,,,,,,,,
Recommendations:,,,,,,,,
In the March 2020 publication (reporting on data upto Q4 2019),,,,,,,,
Outstanding:,,,,,,,,
We publish outstanding using the FF method which excludes BW.,,,,,,,,
"Update only the quarters with incomplete data (ie replacing data relating to 2019 - Q1 missing Durham, Q2 7 courts using old outstanding FF method which had a different case disposal, Q3 imputed)",,,,,,,,
To ensure that it is consistent with our Receipts and Disposals measure the offences allocated using the CCSQ method will be applied to this method.,,,,,,,,
Inform users of proposed changes in teh next bulletin,,,,,,,,
In the June 2010 publication (reporting on data upto Q1 2020 and when we would publish the annual tables),,,,,,,,
RDOS,,,,,,,,
"Look to publish this data using only FF but applying the ccsq methodology updating past data as much as possible - this is to alleviate the strain and resource of reporting from the different sources with in CCS especially in light that SAS may be dicommissioned in the next year which is where the past data is held. Flex the receipt date exclusion which is on most of the queries to see how far a back series we can get (back to 2014 seems fine, but if we can get more it would be beneficial)",,,,,,,,
Other streams:,,,,,,,,
"Develop queries extracting data from the FF - Trials, Plea should be relatively simple, more investigations/resource may be needed for hearing and waiting times. Look at the offence breakdown in FF and compare it with ccsq method.",,,,,,,,
Things we need clarification on:,,,,,,,,
FF offence measure - what are the differences - is it a change in method FF single case flag - what is this dependant on - how much does it flex/move when different stages of the case are reached,,,,,,,,
Common Platform:,,,,,,,,
"The release of this will have a big impact on reporting on Criminal Courts; there are a lot of unknowns, and it is not known whether the data streams that we currently report on will be producable in the way they are now. This could mean that we will need to change what we report on. It would be good to use this opportunity to align all teh measures across DASD so that we are reporting the data not only from teh same source (FF) but also using the same method rather than applying our own queries to the source. Early consultation on measures is recommended so that all parties are involved in creating teh unified definitions of what we should actually be counting.",,,,,,,,
,,,,,,,,
,,,,,,,,
From <https://hub.gke.mybinder.org/user/adamwhitemoj-pr-it-hub-training-c79883va/files/rdos_comparison.html> ,,,,,,,,
